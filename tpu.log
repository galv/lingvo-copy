model_imports.py: Importing asr.librispeech_ctc
model_imports.py: Could not import asr.librispeech_ctc: No module named 'asr'
model_imports.py: Importing lingvo.tasks.asr.params.librispeech_ctc
model_imports.py: Imported lingvo.tasks.asr.params.librispeech_ctc
2020-07-31 06:15:00.670785: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-07-31 06:15:00.670822: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
2020-07-31 06:15:00.670845: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lingvo-tpu-runner): /proc/driver/nvidia/version does not exist
2020-07-31 06:15:00.671773: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:373] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
I0731 06:15:00.676581 140120596608384 trainer.py:1539] Job trainer_client start
model_imports.py: Importing asr.librispeech_ctc
model_imports.py: Could not import asr.librispeech_ctc: No module named 'asr'
model_imports.py: Importing lingvo.tasks.asr.params.librispeech_ctc
model_imports.py: Imported lingvo.tasks.asr.params.librispeech_ctc
I0731 06:15:00.682114 140120596608384 base_runner.py:57] ============================================================
I0731 06:15:00.684628 140120596608384 base_runner.py:59] allow_implicit_capture : NoneType
I0731 06:15:00.684751 140120596608384 base_runner.py:59] cls : type/lingvo.core.base_model/SingleTaskModel
I0731 06:15:00.684829 140120596608384 base_runner.py:59] cluster.add_summary : NoneType
I0731 06:15:00.684884 140120596608384 base_runner.py:59] cluster.cls : type/lingvo.core.cluster/_Cluster
I0731 06:15:00.684925 140120596608384 base_runner.py:59] cluster.controller.cpus_per_replica : 1
I0731 06:15:00.684980 140120596608384 base_runner.py:59] cluster.controller.devices_per_split : 1
I0731 06:15:00.685040 140120596608384 base_runner.py:59] cluster.controller.gpus_per_replica : 0
I0731 06:15:00.685112 140120596608384 base_runner.py:59] cluster.controller.name : '/job:controller'
I0731 06:15:00.685170 140120596608384 base_runner.py:59] cluster.controller.num_tpu_hosts : 0
I0731 06:15:00.685229 140120596608384 base_runner.py:59] cluster.controller.replicas : 1
I0731 06:15:00.685287 140120596608384 base_runner.py:59] cluster.controller.targets : ''
I0731 06:15:00.685352 140120596608384 base_runner.py:59] cluster.controller.tpus_per_replica : 0
I0731 06:15:00.685410 140120596608384 base_runner.py:59] cluster.decoder.cpus_per_replica : 1
I0731 06:15:00.685468 140120596608384 base_runner.py:59] cluster.decoder.devices_per_split : 1
I0731 06:15:00.685526 140120596608384 base_runner.py:59] cluster.decoder.gpus_per_replica : 0
I0731 06:15:00.685584 140120596608384 base_runner.py:59] cluster.decoder.name : '/job:decoder'
I0731 06:15:00.685641 140120596608384 base_runner.py:59] cluster.decoder.num_tpu_hosts : 0
I0731 06:15:00.685699 140120596608384 base_runner.py:59] cluster.decoder.replicas : 0
I0731 06:15:00.685757 140120596608384 base_runner.py:59] cluster.decoder.targets : ''
I0731 06:15:00.685815 140120596608384 base_runner.py:59] cluster.decoder.tpus_per_replica : 0
I0731 06:15:00.685878 140120596608384 base_runner.py:59] cluster.do_eval : False
I0731 06:15:00.685930 140120596608384 base_runner.py:59] cluster.evaler.cpus_per_replica : 1
I0731 06:15:00.685986 140120596608384 base_runner.py:59] cluster.evaler.devices_per_split : 1
I0731 06:15:00.686043 140120596608384 base_runner.py:59] cluster.evaler.gpus_per_replica : 0
I0731 06:15:00.686100 140120596608384 base_runner.py:59] cluster.evaler.name : '/job:evaler'
I0731 06:15:00.686177 140120596608384 base_runner.py:59] cluster.evaler.num_tpu_hosts : 0
I0731 06:15:00.686236 140120596608384 base_runner.py:59] cluster.evaler.replicas : 0
I0731 06:15:00.686301 140120596608384 base_runner.py:59] cluster.evaler.targets : ''
I0731 06:15:00.686360 140120596608384 base_runner.py:59] cluster.evaler.tpus_per_replica : 0
I0731 06:15:00.686419 140120596608384 base_runner.py:59] cluster.input.cpus_per_replica : 1
I0731 06:15:00.686477 140120596608384 base_runner.py:59] cluster.input.devices_per_split : 1
I0731 06:15:00.686534 140120596608384 base_runner.py:59] cluster.input.gpus_per_replica : 0
I0731 06:15:00.686591 140120596608384 base_runner.py:59] cluster.input.name : '/job:input'
I0731 06:15:00.686648 140120596608384 base_runner.py:59] cluster.input.num_tpu_hosts : 0
I0731 06:15:00.686705 140120596608384 base_runner.py:59] cluster.input.replicas : 0
I0731 06:15:00.686764 140120596608384 base_runner.py:59] cluster.input.targets : ''
I0731 06:15:00.686821 140120596608384 base_runner.py:59] cluster.input.tpus_per_replica : 0
I0731 06:15:00.686879 140120596608384 base_runner.py:59] cluster.job : 'trainer_client'
I0731 06:15:00.686935 140120596608384 base_runner.py:59] cluster.logdir : ''
I0731 06:15:00.686996 140120596608384 base_runner.py:59] cluster.mode : 'sync'
I0731 06:15:00.687057 140120596608384 base_runner.py:59] cluster.ps.cpus_per_replica : 1
I0731 06:15:00.687114 140120596608384 base_runner.py:59] cluster.ps.devices_per_split : 1
I0731 06:15:00.687169 140120596608384 base_runner.py:59] cluster.ps.gpus_per_replica : 0
I0731 06:15:00.687226 140120596608384 base_runner.py:59] cluster.ps.name : '/job:trainer_client'
I0731 06:15:00.687291 140120596608384 base_runner.py:59] cluster.ps.num_tpu_hosts : 0
I0731 06:15:00.687353 140120596608384 base_runner.py:59] cluster.ps.replicas : 1
I0731 06:15:00.687410 140120596608384 base_runner.py:59] cluster.ps.targets : ''
I0731 06:15:00.687473 140120596608384 base_runner.py:59] cluster.ps.tpus_per_replica : 0
I0731 06:15:00.687530 140120596608384 base_runner.py:59] cluster.split_id : 0
I0731 06:15:00.687587 140120596608384 base_runner.py:59] cluster.task : 0
I0731 06:15:00.687648 140120596608384 base_runner.py:59] cluster.worker.cpus_per_replica : 1
I0731 06:15:00.687706 140120596608384 base_runner.py:59] cluster.worker.devices_per_split : 1
I0731 06:15:00.687765 140120596608384 base_runner.py:59] cluster.worker.gpus_per_replica : 0
I0731 06:15:00.687823 140120596608384 base_runner.py:59] cluster.worker.name : '/job:trainer_client'
I0731 06:15:00.687895 140120596608384 base_runner.py:59] cluster.worker.num_tpu_hosts : 1
I0731 06:15:00.687955 140120596608384 base_runner.py:59] cluster.worker.replicas : 1
I0731 06:15:00.688013 140120596608384 base_runner.py:59] cluster.worker.targets : 'grpc://10.240.1.2:8470'
I0731 06:15:00.688069 140120596608384 base_runner.py:59] cluster.worker.tpus_per_replica : 8
I0731 06:15:00.688126 140120596608384 base_runner.py:59] dtype : float32
I0731 06:15:00.688183 140120596608384 base_runner.py:59] fprop_dtype : NoneType
I0731 06:15:00.688239 140120596608384 base_runner.py:59] inference_driver_name : NoneType
I0731 06:15:00.688302 140120596608384 base_runner.py:59] input.allow_implicit_capture : NoneType
I0731 06:15:00.688360 140120596608384 base_runner.py:59] input.append_eos_frame : False
I0731 06:15:00.688417 140120596608384 base_runner.py:59] input.bucket_adjust_every_n : 0
I0731 06:15:00.688474 140120596608384 base_runner.py:59] input.bucket_batch_limit : [2]
I0731 06:15:00.688531 140120596608384 base_runner.py:59] input.bucket_upper_bound : [639]
I0731 06:15:00.688587 140120596608384 base_runner.py:59] input.cls : type/lingvo.tasks.asr.input_generator/AsrInput
I0731 06:15:00.688644 140120596608384 base_runner.py:59] input.dtype : float32
I0731 06:15:00.688700 140120596608384 base_runner.py:59] input.file_buffer_size : 10000
I0731 06:15:00.688757 140120596608384 base_runner.py:59] input.file_buffer_size_in_seconds : 0
I0731 06:15:00.688814 140120596608384 base_runner.py:59] input.file_datasource.allow_implicit_capture : NoneType
I0731 06:15:00.688871 140120596608384 base_runner.py:59] input.file_datasource.cls : type/lingvo.core.datasource/PrefixedDataSource
I0731 06:15:00.688935 140120596608384 base_runner.py:59] input.file_datasource.dtype : float32
I0731 06:15:00.688993 140120596608384 base_runner.py:59] input.file_datasource.file_pattern : 'train/train.tfrecords-*'
I0731 06:15:00.689050 140120596608384 base_runner.py:59] input.file_datasource.file_pattern_prefix : 'gs://the-peoples-speech-west-europe/Librispeech'
I0731 06:15:00.689107 140120596608384 base_runner.py:59] input.file_datasource.file_type : 'tfrecord'
I0731 06:15:00.689163 140120596608384 base_runner.py:59] input.file_datasource.fprop_dtype : NoneType
I0731 06:15:00.689219 140120596608384 base_runner.py:59] input.file_datasource.inference_driver_name : NoneType
I0731 06:15:00.689276 140120596608384 base_runner.py:59] input.file_datasource.is_inference : NoneType
I0731 06:15:00.689340 140120596608384 base_runner.py:59] input.file_datasource.name : 'datasource'
I0731 06:15:00.689397 140120596608384 base_runner.py:59] input.file_datasource.params_init.method : 'xavier'
I0731 06:15:00.689454 140120596608384 base_runner.py:59] input.file_datasource.params_init.scale : 1.000001
I0731 06:15:00.689511 140120596608384 base_runner.py:59] input.file_datasource.params_init.seed : NoneType
I0731 06:15:00.689568 140120596608384 base_runner.py:59] input.file_datasource.random_seed : NoneType
I0731 06:15:00.689625 140120596608384 base_runner.py:59] input.file_datasource.skip_lp_regularization : NoneType
I0731 06:15:00.689681 140120596608384 base_runner.py:59] input.file_datasource.vn.global_vn : False
I0731 06:15:00.689738 140120596608384 base_runner.py:59] input.file_datasource.vn.per_step_vn : False
I0731 06:15:00.689795 140120596608384 base_runner.py:59] input.file_datasource.vn.scale : NoneType
I0731 06:15:00.689854 140120596608384 base_runner.py:59] input.file_datasource.vn.seed : NoneType
I0731 06:15:00.689911 140120596608384 base_runner.py:59] input.file_parallelism : 16
I0731 06:15:00.689968 140120596608384 base_runner.py:59] input.file_pattern : ''
I0731 06:15:00.690025 140120596608384 base_runner.py:59] input.file_random_seed : 0
I0731 06:15:00.690082 140120596608384 base_runner.py:59] input.flush_every_n : 0
I0731 06:15:00.690139 140120596608384 base_runner.py:59] input.fprop_dtype : NoneType
I0731 06:15:00.690195 140120596608384 base_runner.py:59] input.frame_size : 80
I0731 06:15:00.690251 140120596608384 base_runner.py:59] input.inference_driver_name : NoneType
I0731 06:15:00.690313 140120596608384 base_runner.py:59] input.is_inference : NoneType
I0731 06:15:00.690371 140120596608384 base_runner.py:59] input.name : 'input'
I0731 06:15:00.690428 140120596608384 base_runner.py:59] input.num_batcher_threads : 1
I0731 06:15:00.690485 140120596608384 base_runner.py:59] input.num_partitions : NoneType
I0731 06:15:00.690541 140120596608384 base_runner.py:59] input.num_samples : 281241
I0731 06:15:00.690598 140120596608384 base_runner.py:59] input.pad_to_max_seq_length : True
I0731 06:15:00.690655 140120596608384 base_runner.py:59] input.params_init.method : 'xavier'
I0731 06:15:00.690711 140120596608384 base_runner.py:59] input.params_init.scale : 1.000001
I0731 06:15:00.690768 140120596608384 base_runner.py:59] input.params_init.seed : NoneType
I0731 06:15:00.690825 140120596608384 base_runner.py:59] input.random_seed : NoneType
I0731 06:15:00.690881 140120596608384 base_runner.py:59] input.remote.max_inflights_per_target : 32
I0731 06:15:00.690939 140120596608384 base_runner.py:59] input.remote.shardable_batch : False
I0731 06:15:00.690995 140120596608384 base_runner.py:59] input.repeat_count : -1
I0731 06:15:00.691065 140120596608384 base_runner.py:59] input.require_sequential_order : False
I0731 06:15:00.691123 140120596608384 base_runner.py:59] input.skip_lp_regularization : NoneType
I0731 06:15:00.691180 140120596608384 base_runner.py:59] input.source_max_length : 639
I0731 06:15:00.691237 140120596608384 base_runner.py:59] input.target_max_length : 300
I0731 06:15:00.691299 140120596608384 base_runner.py:59] input.tokenizer.allow_implicit_capture : NoneType
I0731 06:15:00.691357 140120596608384 base_runner.py:59] input.tokenizer.append_eos : True
I0731 06:15:00.691415 140120596608384 base_runner.py:59] input.tokenizer.cls : type/lingvo.core.tokenizers/AsciiTokenizer
I0731 06:15:00.691472 140120596608384 base_runner.py:59] input.tokenizer.dtype : float32
I0731 06:15:00.691529 140120596608384 base_runner.py:59] input.tokenizer.fprop_dtype : NoneType
I0731 06:15:00.691586 140120596608384 base_runner.py:59] input.tokenizer.inference_driver_name : NoneType
I0731 06:15:00.691642 140120596608384 base_runner.py:59] input.tokenizer.is_inference : NoneType
I0731 06:15:00.691699 140120596608384 base_runner.py:59] input.tokenizer.name : 'tokenizer'
I0731 06:15:00.691756 140120596608384 base_runner.py:59] input.tokenizer.pad_to_max_length : True
I0731 06:15:00.691813 140120596608384 base_runner.py:59] input.tokenizer.params_init.method : 'xavier'
I0731 06:15:00.691869 140120596608384 base_runner.py:59] input.tokenizer.params_init.scale : 1.000001
I0731 06:15:00.691940 140120596608384 base_runner.py:59] input.tokenizer.params_init.seed : NoneType
I0731 06:15:00.691998 140120596608384 base_runner.py:59] input.tokenizer.random_seed : NoneType
I0731 06:15:00.692055 140120596608384 base_runner.py:59] input.tokenizer.skip_lp_regularization : NoneType
I0731 06:15:00.692112 140120596608384 base_runner.py:59] input.tokenizer.target_eos_id : 2
I0731 06:15:00.692168 140120596608384 base_runner.py:59] input.tokenizer.target_sos_id : 1
I0731 06:15:00.692225 140120596608384 base_runner.py:59] input.tokenizer.target_unk_id : 0
I0731 06:15:00.692289 140120596608384 base_runner.py:59] input.tokenizer.target_wb_id : -1
I0731 06:15:00.692350 140120596608384 base_runner.py:59] input.tokenizer.vn.global_vn : False
I0731 06:15:00.692408 140120596608384 base_runner.py:59] input.tokenizer.vn.per_step_vn : False
I0731 06:15:00.692464 140120596608384 base_runner.py:59] input.tokenizer.vn.scale : NoneType
I0731 06:15:00.692521 140120596608384 base_runner.py:59] input.tokenizer.vn.seed : NoneType
I0731 06:15:00.692578 140120596608384 base_runner.py:59] input.tokenizer.vocab_size : 76
I0731 06:15:00.692635 140120596608384 base_runner.py:59] input.tokenizer_dict : {}
I0731 06:15:00.692692 140120596608384 base_runner.py:59] input.tpu_infeed_parallelism : 1
I0731 06:15:00.692748 140120596608384 base_runner.py:59] input.use_chaining : False
I0731 06:15:00.692806 140120596608384 base_runner.py:59] input.use_partitioned_infeed_queue : False
I0731 06:15:00.692863 140120596608384 base_runner.py:59] input.use_per_host_infeed : False
I0731 06:15:00.692920 140120596608384 base_runner.py:59] input.use_within_batch_mixing : False
I0731 06:15:00.692977 140120596608384 base_runner.py:59] input.vn.global_vn : False
I0731 06:15:00.693033 140120596608384 base_runner.py:59] input.vn.per_step_vn : False
I0731 06:15:00.693090 140120596608384 base_runner.py:59] input.vn.scale : NoneType
I0731 06:15:00.693148 140120596608384 base_runner.py:59] input.vn.seed : NoneType
I0731 06:15:00.693204 140120596608384 base_runner.py:59] is_inference : NoneType
I0731 06:15:00.693261 140120596608384 base_runner.py:59] model : 'asr.librispeech_ctc.Librispeech960Base@/home/ws15dgalvez/lingvo-copy/bazel-bin/lingvo/trainer.runfiles/__main__/lingvo/tasks/asr/params/librispeech_ctc.py:21'
I0731 06:15:00.693326 140120596608384 base_runner.py:59] name : ''
I0731 06:15:00.693385 140120596608384 base_runner.py:59] params_init.method : 'xavier'
I0731 06:15:00.693443 140120596608384 base_runner.py:59] params_init.scale : 1.000001
I0731 06:15:00.693499 140120596608384 base_runner.py:59] params_init.seed : NoneType
I0731 06:15:00.693556 140120596608384 base_runner.py:59] random_seed : NoneType
I0731 06:15:00.693613 140120596608384 base_runner.py:59] skip_lp_regularization : NoneType
I0731 06:15:00.693670 140120596608384 base_runner.py:59] task.allow_implicit_capture : NoneType
I0731 06:15:00.693726 140120596608384 base_runner.py:59] task.cls : type/lingvo.tasks.asr.ctc_model/CTCModel
I0731 06:15:00.693783 140120596608384 base_runner.py:59] task.decoder : NoneType
I0731 06:15:00.693839 140120596608384 base_runner.py:59] task.dtype : float32
I0731 06:15:00.693895 140120596608384 base_runner.py:59] task.encoder : NoneType
I0731 06:15:00.693952 140120596608384 base_runner.py:59] task.eval.decoder_samples_per_summary : 0
I0731 06:15:00.694007 140120596608384 base_runner.py:59] task.eval.load_checkpoint_from : NoneType
I0731 06:15:00.694063 140120596608384 base_runner.py:59] task.eval.samples_per_summary : 5000
I0731 06:15:00.694121 140120596608384 base_runner.py:59] task.eval.start_decoder_after : 0
I0731 06:15:00.694178 140120596608384 base_runner.py:59] task.eval.start_eval_after : 0
I0731 06:15:00.694234 140120596608384 base_runner.py:59] task.fprop_dtype : NoneType
I0731 06:15:00.694290 140120596608384 base_runner.py:59] task.frontend : NoneType
I0731 06:15:00.694353 140120596608384 base_runner.py:59] task.include_auxiliary_metrics : True
I0731 06:15:00.694409 140120596608384 base_runner.py:59] task.inference_driver_name : NoneType
I0731 06:15:00.694466 140120596608384 base_runner.py:59] task.input : NoneType
I0731 06:15:00.694523 140120596608384 base_runner.py:59] task.input_dim : 80
I0731 06:15:00.694580 140120596608384 base_runner.py:59] task.is_inference : NoneType
I0731 06:15:00.694637 140120596608384 base_runner.py:59] task.layer_index_before_stacking : -1
I0731 06:15:00.694693 140120596608384 base_runner.py:59] task.lstm_cell_size : 64
I0731 06:15:00.694750 140120596608384 base_runner.py:59] task.lstm_tpl.allow_implicit_capture : NoneType
I0731 06:15:00.694806 140120596608384 base_runner.py:59] task.lstm_tpl.apply_pruning : False
I0731 06:15:00.694863 140120596608384 base_runner.py:59] task.lstm_tpl.apply_pruning_to_projection : False
I0731 06:15:00.694919 140120596608384 base_runner.py:59] task.lstm_tpl.bias_init.method : 'constant'
I0731 06:15:00.694976 140120596608384 base_runner.py:59] task.lstm_tpl.bias_init.scale : 0.0
I0731 06:15:00.695033 140120596608384 base_runner.py:59] task.lstm_tpl.bias_init.seed : 0
I0731 06:15:00.695090 140120596608384 base_runner.py:59] task.lstm_tpl.cell_value_cap : 10.0
I0731 06:15:00.695147 140120596608384 base_runner.py:59] task.lstm_tpl.cls : type/lingvo.core.rnn_cell/LSTMCellSimple
I0731 06:15:00.695204 140120596608384 base_runner.py:59] task.lstm_tpl.couple_input_forget_gates : False
I0731 06:15:00.695260 140120596608384 base_runner.py:59] task.lstm_tpl.dtype : float32
I0731 06:15:00.695321 140120596608384 base_runner.py:59] task.lstm_tpl.enable_lstm_bias : True
I0731 06:15:00.695378 140120596608384 base_runner.py:59] task.lstm_tpl.forget_gate_bias : 0.0
I0731 06:15:00.695435 140120596608384 base_runner.py:59] task.lstm_tpl.fprop_dtype : NoneType
I0731 06:15:00.695491 140120596608384 base_runner.py:59] task.lstm_tpl.gradient_pruning : False
I0731 06:15:00.695547 140120596608384 base_runner.py:59] task.lstm_tpl.inference_driver_name : NoneType
I0731 06:15:00.695604 140120596608384 base_runner.py:59] task.lstm_tpl.inputs_arity : 1
I0731 06:15:00.695660 140120596608384 base_runner.py:59] task.lstm_tpl.is_inference : NoneType
I0731 06:15:00.695717 140120596608384 base_runner.py:59] task.lstm_tpl.name : ''
I0731 06:15:00.695773 140120596608384 base_runner.py:59] task.lstm_tpl.num_hidden_nodes : 0
I0731 06:15:00.695830 140120596608384 base_runner.py:59] task.lstm_tpl.num_input_nodes : 0
I0731 06:15:00.695897 140120596608384 base_runner.py:59] task.lstm_tpl.num_output_nodes : 0
I0731 06:15:00.695956 140120596608384 base_runner.py:59] task.lstm_tpl.output_nonlinearity : True
I0731 06:15:00.696014 140120596608384 base_runner.py:59] task.lstm_tpl.params_init.method : 'xavier'
I0731 06:15:00.696072 140120596608384 base_runner.py:59] task.lstm_tpl.params_init.scale : 1.000001
I0731 06:15:00.696129 140120596608384 base_runner.py:59] task.lstm_tpl.params_init.seed : NoneType
I0731 06:15:00.696186 140120596608384 base_runner.py:59] task.lstm_tpl.qdomain.c_state : NoneType
I0731 06:15:00.696242 140120596608384 base_runner.py:59] task.lstm_tpl.qdomain.default : NoneType
I0731 06:15:00.696306 140120596608384 base_runner.py:59] task.lstm_tpl.qdomain.fullyconnected : NoneType
I0731 06:15:00.696364 140120596608384 base_runner.py:59] task.lstm_tpl.qdomain.m_state : NoneType
I0731 06:15:00.696423 140120596608384 base_runner.py:59] task.lstm_tpl.qdomain.weight : NoneType
I0731 06:15:00.696481 140120596608384 base_runner.py:59] task.lstm_tpl.random_seed : NoneType
I0731 06:15:00.696539 140120596608384 base_runner.py:59] task.lstm_tpl.reset_cell_state : False
I0731 06:15:00.696597 140120596608384 base_runner.py:59] task.lstm_tpl.skip_lp_regularization : NoneType
I0731 06:15:00.696661 140120596608384 base_runner.py:59] task.lstm_tpl.vn.global_vn : False
I0731 06:15:00.696720 140120596608384 base_runner.py:59] task.lstm_tpl.vn.per_step_vn : False
I0731 06:15:00.696778 140120596608384 base_runner.py:59] task.lstm_tpl.vn.scale : NoneType
I0731 06:15:00.696835 140120596608384 base_runner.py:59] task.lstm_tpl.vn.seed : NoneType
I0731 06:15:00.696893 140120596608384 base_runner.py:59] task.lstm_tpl.zero_state_init_params.method : 'zeros'
I0731 06:15:00.696949 140120596608384 base_runner.py:59] task.lstm_tpl.zero_state_init_params.seed : NoneType
I0731 06:15:00.697005 140120596608384 base_runner.py:59] task.lstm_tpl.zo_prob : 0.0
I0731 06:15:00.697063 140120596608384 base_runner.py:59] task.name : 'librispeech'
I0731 06:15:00.697119 140120596608384 base_runner.py:59] task.num_lstm_layers : 1
I0731 06:15:00.697177 140120596608384 base_runner.py:59] task.online_encoder : NoneType
I0731 06:15:00.697233 140120596608384 base_runner.py:59] task.params_init.method : 'xavier'
I0731 06:15:00.697359 140120596608384 base_runner.py:59] task.params_init.scale : 1.000001
I0731 06:15:00.697396 140120596608384 base_runner.py:59] task.params_init.seed : NoneType
I0731 06:15:00.697435 140120596608384 base_runner.py:59] task.proj_tpl.activation : 'RELU'
I0731 06:15:00.697494 140120596608384 base_runner.py:59] task.proj_tpl.affine_last : False
I0731 06:15:00.697535 140120596608384 base_runner.py:59] task.proj_tpl.allow_implicit_capture : NoneType
I0731 06:15:00.697571 140120596608384 base_runner.py:59] task.proj_tpl.apply_pruning : False
I0731 06:15:00.697607 140120596608384 base_runner.py:59] task.proj_tpl.batch_norm : False
I0731 06:15:00.697643 140120596608384 base_runner.py:59] task.proj_tpl.bias_init : 0.0
I0731 06:15:00.697679 140120596608384 base_runner.py:59] task.proj_tpl.bn_fold_weights : NoneType
I0731 06:15:00.697716 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.add_stats_to_moving_average_variables : NoneType
I0731 06:15:00.697753 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.allow_implicit_capture : NoneType
I0731 06:15:00.697788 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.cls : type/lingvo.core.bn_layers/BatchNormLayer
I0731 06:15:00.697824 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.decay : 0.999
I0731 06:15:00.697860 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.dim : 0
I0731 06:15:00.697901 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.dtype : float32
I0731 06:15:00.697934 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.enable_cross_replica_sum_on_tpu : True
I0731 06:15:00.697979 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.fprop_dtype : NoneType
I0731 06:15:00.698033 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.gamma_zero_init : False
I0731 06:15:00.698090 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.inference_driver_name : NoneType
I0731 06:15:00.698148 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.is_inference : NoneType
I0731 06:15:00.698205 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.name : ''
I0731 06:15:00.698263 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.params_init.method : 'xavier'
I0731 06:15:00.698327 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.params_init.scale : 1.000001
I0731 06:15:00.698386 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.params_init.seed : NoneType
I0731 06:15:00.698443 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.random_seed : NoneType
I0731 06:15:00.698500 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.set_padded_output_to_zero : True
I0731 06:15:00.698556 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.skip_lp_regularization : NoneType
I0731 06:15:00.698614 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.use_fused_batch_norm_for_eval : False
I0731 06:15:00.698670 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.use_moving_avg_in_training : False
I0731 06:15:00.698728 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.vn.global_vn : False
I0731 06:15:00.698785 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.vn.per_step_vn : False
I0731 06:15:00.698841 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.vn.scale : NoneType
I0731 06:15:00.698897 140120596608384 base_runner.py:59] task.proj_tpl.bn_params.vn.seed : NoneType
I0731 06:15:00.698954 140120596608384 base_runner.py:59] task.proj_tpl.cls : type/lingvo.core.layers/ProjectionLayer
I0731 06:15:00.699010 140120596608384 base_runner.py:59] task.proj_tpl.dtype : float32
I0731 06:15:00.699067 140120596608384 base_runner.py:59] task.proj_tpl.fprop_dtype : NoneType
I0731 06:15:00.699125 140120596608384 base_runner.py:59] task.proj_tpl.has_bias : False
I0731 06:15:00.699182 140120596608384 base_runner.py:59] task.proj_tpl.inference_driver_name : NoneType
I0731 06:15:00.699240 140120596608384 base_runner.py:59] task.proj_tpl.input_dim : 0
I0731 06:15:00.699303 140120596608384 base_runner.py:59] task.proj_tpl.is_inference : NoneType
I0731 06:15:00.699361 140120596608384 base_runner.py:59] task.proj_tpl.name : ''
I0731 06:15:00.699419 140120596608384 base_runner.py:59] task.proj_tpl.output_dim : 0
I0731 06:15:00.699476 140120596608384 base_runner.py:59] task.proj_tpl.params_init.method : 'xavier'
I0731 06:15:00.699532 140120596608384 base_runner.py:59] task.proj_tpl.params_init.scale : 1.000001
I0731 06:15:00.699588 140120596608384 base_runner.py:59] task.proj_tpl.params_init.seed : NoneType
I0731 06:15:00.699645 140120596608384 base_runner.py:59] task.proj_tpl.qdomain.default : NoneType
I0731 06:15:00.699702 140120596608384 base_runner.py:59] task.proj_tpl.random_seed : NoneType
I0731 06:15:00.699759 140120596608384 base_runner.py:59] task.proj_tpl.skip_lp_regularization : NoneType
I0731 06:15:00.699816 140120596608384 base_runner.py:59] task.proj_tpl.use_einsum : False
I0731 06:15:00.699883 140120596608384 base_runner.py:59] task.proj_tpl.vn.global_vn : False
I0731 06:15:00.699944 140120596608384 base_runner.py:59] task.proj_tpl.vn.per_step_vn : False
I0731 06:15:00.700003 140120596608384 base_runner.py:59] task.proj_tpl.vn.scale : NoneType
I0731 06:15:00.700061 140120596608384 base_runner.py:59] task.proj_tpl.vn.seed : NoneType
I0731 06:15:00.700118 140120596608384 base_runner.py:59] task.proj_tpl.weight_norm : False
I0731 06:15:00.700175 140120596608384 base_runner.py:59] task.project_lstm_output : False
I0731 06:15:00.700233 140120596608384 base_runner.py:59] task.random_seed : NoneType
I0731 06:15:00.700291 140120596608384 base_runner.py:59] task.skip_lp_regularization : NoneType
I0731 06:15:00.700355 140120596608384 base_runner.py:59] task.stacking_layer_tpl.allow_implicit_capture : NoneType
I0731 06:15:00.700413 140120596608384 base_runner.py:59] task.stacking_layer_tpl.cls : type/lingvo.core.layers/StackingOverTime
I0731 06:15:00.700470 140120596608384 base_runner.py:59] task.stacking_layer_tpl.dtype : float32
I0731 06:15:00.700528 140120596608384 base_runner.py:59] task.stacking_layer_tpl.fprop_dtype : NoneType
I0731 06:15:00.700584 140120596608384 base_runner.py:59] task.stacking_layer_tpl.inference_driver_name : NoneType
I0731 06:15:00.700641 140120596608384 base_runner.py:59] task.stacking_layer_tpl.is_inference : NoneType
I0731 06:15:00.700699 140120596608384 base_runner.py:59] task.stacking_layer_tpl.left_context : 0
I0731 06:15:00.700757 140120596608384 base_runner.py:59] task.stacking_layer_tpl.name : ''
I0731 06:15:00.700814 140120596608384 base_runner.py:59] task.stacking_layer_tpl.params_init.method : 'xavier'
I0731 06:15:00.700870 140120596608384 base_runner.py:59] task.stacking_layer_tpl.params_init.scale : 1.000001
I0731 06:15:00.700927 140120596608384 base_runner.py:59] task.stacking_layer_tpl.params_init.seed : NoneType
I0731 06:15:00.700984 140120596608384 base_runner.py:59] task.stacking_layer_tpl.random_seed : NoneType
I0731 06:15:00.701041 140120596608384 base_runner.py:59] task.stacking_layer_tpl.right_context : 0
I0731 06:15:00.701098 140120596608384 base_runner.py:59] task.stacking_layer_tpl.skip_lp_regularization : NoneType
I0731 06:15:00.701154 140120596608384 base_runner.py:59] task.stacking_layer_tpl.stride : 1
I0731 06:15:00.701210 140120596608384 base_runner.py:59] task.stacking_layer_tpl.vn.global_vn : False
I0731 06:15:00.701267 140120596608384 base_runner.py:59] task.stacking_layer_tpl.vn.per_step_vn : False
I0731 06:15:00.701330 140120596608384 base_runner.py:59] task.stacking_layer_tpl.vn.scale : NoneType
I0731 06:15:00.701389 140120596608384 base_runner.py:59] task.stacking_layer_tpl.vn.seed : NoneType
I0731 06:15:00.701447 140120596608384 base_runner.py:59] task.task_global_step : False
I0731 06:15:00.701503 140120596608384 base_runner.py:59] task.train.bprop_variable_exclusion : NoneType
I0731 06:15:00.701560 140120596608384 base_runner.py:59] task.train.bprop_variable_filter : NoneType
I0731 06:15:00.701617 140120596608384 base_runner.py:59] task.train.clip_gradient_norm_to_value : 1.0
I0731 06:15:00.701674 140120596608384 base_runner.py:59] task.train.clip_gradient_single_norm_to_value : 0.0
I0731 06:15:00.701731 140120596608384 base_runner.py:59] task.train.colocate_gradients_with_ops : True
I0731 06:15:00.701788 140120596608384 base_runner.py:59] task.train.early_stop.metric_history.jobname : 'eval_dev'
I0731 06:15:00.701845 140120596608384 base_runner.py:59] task.train.early_stop.metric_history.local_filesystem : False
I0731 06:15:00.701909 140120596608384 base_runner.py:59] task.train.early_stop.metric_history.logdir : ''
I0731 06:15:00.701968 140120596608384 base_runner.py:59] task.train.early_stop.metric_history.metric : 'log_pplx'
I0731 06:15:00.702025 140120596608384 base_runner.py:59] task.train.early_stop.metric_history.minimize : True
I0731 06:15:00.702082 140120596608384 base_runner.py:59] task.train.early_stop.metric_history.name : 'MetricHistory'
I0731 06:15:00.702139 140120596608384 base_runner.py:59] task.train.early_stop.metric_history.tfevent_file : False
I0731 06:15:00.702195 140120596608384 base_runner.py:59] task.train.early_stop.min_steps : 0
I0731 06:15:00.702253 140120596608384 base_runner.py:59] task.train.early_stop.name : 'EarlyStop'
I0731 06:15:00.702343 140120596608384 base_runner.py:59] task.train.early_stop.tolerance : 0.0
I0731 06:15:00.702395 140120596608384 base_runner.py:59] task.train.early_stop.verbose : True
I0731 06:15:00.702454 140120596608384 base_runner.py:59] task.train.early_stop.window : 0
I0731 06:15:00.702512 140120596608384 base_runner.py:59] task.train.ema_decay : 0.0
I0731 06:15:00.702570 140120596608384 base_runner.py:59] task.train.ema_decay_moving_vars : NoneType
I0731 06:15:00.702627 140120596608384 base_runner.py:59] task.train.enqueue_max_steps : -1
I0731 06:15:00.702684 140120596608384 base_runner.py:59] task.train.gate_gradients : False
I0731 06:15:00.702742 140120596608384 base_runner.py:59] task.train.grad_aggregation_method : 1
I0731 06:15:00.702801 140120596608384 base_runner.py:59] task.train.grad_norm_to_clip_to_zero : 100.0
I0731 06:15:00.702859 140120596608384 base_runner.py:59] task.train.grad_norm_tracker : NoneType
I0731 06:15:00.702915 140120596608384 base_runner.py:59] task.train.init_from_checkpoint_rules : {}
I0731 06:15:00.702972 140120596608384 base_runner.py:59] task.train.l1_regularizer_weight : NoneType
I0731 06:15:00.703028 140120596608384 base_runner.py:59] task.train.l2_regularizer_weight : NoneType
I0731 06:15:00.703085 140120596608384 base_runner.py:59] task.train.learner : NoneType
I0731 06:15:00.703142 140120596608384 base_runner.py:59] task.train.learning_rate : 0.00025
I0731 06:15:00.703198 140120596608384 base_runner.py:59] task.train.lr_schedule.allow_implicit_capture : NoneType
I0731 06:15:00.703255 140120596608384 base_runner.py:59] task.train.lr_schedule.cls : type/lingvo.core.schedule/ContinuousSchedule
I0731 06:15:00.703318 140120596608384 base_runner.py:59] task.train.lr_schedule.dtype : float32
I0731 06:15:00.703377 140120596608384 base_runner.py:59] task.train.lr_schedule.fprop_dtype : NoneType
I0731 06:15:00.703434 140120596608384 base_runner.py:59] task.train.lr_schedule.half_life_steps : 100000
I0731 06:15:00.703491 140120596608384 base_runner.py:59] task.train.lr_schedule.inference_driver_name : NoneType
I0731 06:15:00.703547 140120596608384 base_runner.py:59] task.train.lr_schedule.initial_value : 1.0
I0731 06:15:00.703603 140120596608384 base_runner.py:59] task.train.lr_schedule.is_inference : NoneType
I0731 06:15:00.703661 140120596608384 base_runner.py:59] task.train.lr_schedule.min : 0.01
I0731 06:15:00.703718 140120596608384 base_runner.py:59] task.train.lr_schedule.name : 'LRSched'
I0731 06:15:00.703775 140120596608384 base_runner.py:59] task.train.lr_schedule.params_init.method : 'xavier'
I0731 06:15:00.703832 140120596608384 base_runner.py:59] task.train.lr_schedule.params_init.scale : 1.000001
I0731 06:15:00.703905 140120596608384 base_runner.py:59] task.train.lr_schedule.params_init.seed : NoneType
I0731 06:15:00.703967 140120596608384 base_runner.py:59] task.train.lr_schedule.random_seed : NoneType
I0731 06:15:00.704027 140120596608384 base_runner.py:59] task.train.lr_schedule.skip_lp_regularization : NoneType
I0731 06:15:00.704085 140120596608384 base_runner.py:59] task.train.lr_schedule.start_step : 50000
I0731 06:15:00.704142 140120596608384 base_runner.py:59] task.train.lr_schedule.vn.global_vn : False
I0731 06:15:00.704199 140120596608384 base_runner.py:59] task.train.lr_schedule.vn.per_step_vn : False
I0731 06:15:00.704256 140120596608384 base_runner.py:59] task.train.lr_schedule.vn.scale : NoneType
I0731 06:15:00.704319 140120596608384 base_runner.py:59] task.train.lr_schedule.vn.seed : NoneType
I0731 06:15:00.704377 140120596608384 base_runner.py:59] task.train.max_steps : 4000000
I0731 06:15:00.704434 140120596608384 base_runner.py:59] task.train.optimizer.allow_implicit_capture : NoneType
I0731 06:15:00.704491 140120596608384 base_runner.py:59] task.train.optimizer.beta1 : 0.9
I0731 06:15:00.704548 140120596608384 base_runner.py:59] task.train.optimizer.beta2 : 0.999
I0731 06:15:00.704606 140120596608384 base_runner.py:59] task.train.optimizer.cls : type/lingvo.core.optimizer/Adam
I0731 06:15:00.704663 140120596608384 base_runner.py:59] task.train.optimizer.dtype : float32
I0731 06:15:00.704720 140120596608384 base_runner.py:59] task.train.optimizer.epsilon : 1e-06
I0731 06:15:00.704781 140120596608384 base_runner.py:59] task.train.optimizer.fprop_dtype : NoneType
I0731 06:15:00.704824 140120596608384 base_runner.py:59] task.train.optimizer.inference_driver_name : NoneType
I0731 06:15:00.704882 140120596608384 base_runner.py:59] task.train.optimizer.is_inference : NoneType
I0731 06:15:00.704939 140120596608384 base_runner.py:59] task.train.optimizer.name : 'Adam'
I0731 06:15:00.704996 140120596608384 base_runner.py:59] task.train.optimizer.params_init.method : 'xavier'
I0731 06:15:00.705054 140120596608384 base_runner.py:59] task.train.optimizer.params_init.scale : 1.000001
I0731 06:15:00.705111 140120596608384 base_runner.py:59] task.train.optimizer.params_init.seed : NoneType
I0731 06:15:00.705168 140120596608384 base_runner.py:59] task.train.optimizer.random_seed : NoneType
I0731 06:15:00.705224 140120596608384 base_runner.py:59] task.train.optimizer.skip_lp_regularization : NoneType
I0731 06:15:00.705281 140120596608384 base_runner.py:59] task.train.optimizer.use_bf16_gradients_ar : False
I0731 06:15:00.705344 140120596608384 base_runner.py:59] task.train.optimizer.vn.global_vn : False
I0731 06:15:00.705402 140120596608384 base_runner.py:59] task.train.optimizer.vn.per_step_vn : False
I0731 06:15:00.705459 140120596608384 base_runner.py:59] task.train.optimizer.vn.scale : NoneType
I0731 06:15:00.705517 140120596608384 base_runner.py:59] task.train.optimizer.vn.seed : NoneType
I0731 06:15:00.705573 140120596608384 base_runner.py:59] task.train.pruning_hparams_dict : NoneType
I0731 06:15:00.705631 140120596608384 base_runner.py:59] task.train.save_interval_seconds : 600
I0731 06:15:00.705688 140120596608384 base_runner.py:59] task.train.save_keep_checkpoint_every_n_hours : 0.5
I0731 06:15:00.705743 140120596608384 base_runner.py:59] task.train.save_max_to_keep : 100
I0731 06:15:00.705801 140120596608384 base_runner.py:59] task.train.scale_gradients : False
I0731 06:15:00.705859 140120596608384 base_runner.py:59] task.train.start_up_delay_steps : 200
I0731 06:15:00.705924 140120596608384 base_runner.py:59] task.train.summary_interval_steps : 100
I0731 06:15:00.705982 140120596608384 base_runner.py:59] task.train.tpu_steps_per_loop : 20
I0731 06:15:00.706040 140120596608384 base_runner.py:59] task.train.vn_start_step : 20000
I0731 06:15:00.706097 140120596608384 base_runner.py:59] task.train.vn_std : 0.075
I0731 06:15:00.706172 140120596608384 base_runner.py:59] task.unidi_rnn_type : 'func'
I0731 06:15:00.706233 140120596608384 base_runner.py:59] task.vn.global_vn : False
I0731 06:15:00.706291 140120596608384 base_runner.py:59] task.vn.per_step_vn : False
I0731 06:15:00.706356 140120596608384 base_runner.py:59] task.vn.scale : NoneType
I0731 06:15:00.706413 140120596608384 base_runner.py:59] task.vn.seed : NoneType
I0731 06:15:00.706470 140120596608384 base_runner.py:59] task.vocab_epsilon_index : 73
I0731 06:15:00.706527 140120596608384 base_runner.py:59] task.vocab_size : 76
I0731 06:15:00.706585 140120596608384 base_runner.py:59] train.early_stop.metric_history.jobname : 'eval_dev'
I0731 06:15:00.706643 140120596608384 base_runner.py:59] train.early_stop.metric_history.local_filesystem : False
I0731 06:15:00.706701 140120596608384 base_runner.py:59] train.early_stop.metric_history.logdir : ''
I0731 06:15:00.706758 140120596608384 base_runner.py:59] train.early_stop.metric_history.metric : 'log_pplx'
I0731 06:15:00.706816 140120596608384 base_runner.py:59] train.early_stop.metric_history.minimize : True
I0731 06:15:00.706874 140120596608384 base_runner.py:59] train.early_stop.metric_history.name : 'MetricHistory'
I0731 06:15:00.706931 140120596608384 base_runner.py:59] train.early_stop.metric_history.tfevent_file : False
I0731 06:15:00.706988 140120596608384 base_runner.py:59] train.early_stop.min_steps : 0
I0731 06:15:00.707045 140120596608384 base_runner.py:59] train.early_stop.name : 'EarlyStop'
I0731 06:15:00.707101 140120596608384 base_runner.py:59] train.early_stop.tolerance : 0.0
I0731 06:15:00.707159 140120596608384 base_runner.py:59] train.early_stop.verbose : True
I0731 06:15:00.707215 140120596608384 base_runner.py:59] train.early_stop.window : 0
I0731 06:15:00.707279 140120596608384 base_runner.py:59] train.ema_decay : 0.0
I0731 06:15:00.707350 140120596608384 base_runner.py:59] train.ema_decay_moving_vars : NoneType
I0731 06:15:00.707410 140120596608384 base_runner.py:59] train.enqueue_max_steps : -1
I0731 06:15:00.707468 140120596608384 base_runner.py:59] train.init_from_checkpoint_rules : {}
I0731 06:15:00.707525 140120596608384 base_runner.py:59] train.max_steps : 4000000
I0731 06:15:00.707583 140120596608384 base_runner.py:59] train.save_interval_seconds : 600
I0731 06:15:00.707640 140120596608384 base_runner.py:59] train.save_keep_checkpoint_every_n_hours : 0.5
I0731 06:15:00.707697 140120596608384 base_runner.py:59] train.save_max_to_keep : 100
I0731 06:15:00.707754 140120596608384 base_runner.py:59] train.start_up_delay_steps : 200
I0731 06:15:00.707811 140120596608384 base_runner.py:59] train.summary_interval_steps : 100
I0731 06:15:00.707869 140120596608384 base_runner.py:59] train.tpu_steps_per_loop : 20
I0731 06:15:00.707940 140120596608384 base_runner.py:59] vn.global_vn : False
I0731 06:15:00.707998 140120596608384 base_runner.py:59] vn.per_step_vn : False
I0731 06:15:00.708061 140120596608384 base_runner.py:59] vn.scale : NoneType
I0731 06:15:00.708119 140120596608384 base_runner.py:59] vn.seed : NoneType
I0731 06:15:00.708177 140120596608384 base_runner.py:59] 
I0731 06:15:00.708251 140120596608384 base_runner.py:60] ============================================================
I0731 06:15:00.709710 140120596608384 base_runner.py:111] Starting ...
I0731 06:15:00.709852 140120596608384 trainer.py:526] data_parallelism: 8, num_devices_per_split: 1
I0731 06:15:00.710056 140120596608384 trainer.py:538] Creating TrainerTpu using data parallelism 8 and 20 steps_per_loop
INFO:tensorflow:enable_2d_tiling: False
I0731 06:15:10.174555 140120596608384 device_assignment.py:351] enable_2d_tiling: False
I0731 06:15:10.175350 140120596608384 trainer.py:565] device_assignment.core_assignment: [[[0 0 0]]

 [[0 0 1]]

 [[0 1 0]]

 [[0 1 1]]

 [[1 0 0]]

 [[1 0 1]]

 [[1 1 0]]

 [[1 1 1]]]
I0731 06:15:10.175600 140120596608384 trainer.py:567] device_assignment.topology.device_coordinates: [[[0 0 0]
  [0 0 1]
  [1 0 0]
  [1 0 1]
  [0 1 0]
  [0 1 1]
  [1 1 0]
  [1 1 1]]]
I0731 06:15:10.186862 140120596608384 base_input_generator.py:675] Building data source <lingvo.core.datasource.PrefixedDataSource object at 0x7f6fcacb5bd0> with params {
  allow_implicit_capture: None
  cls: <class 'lingvo.core.datasource.PrefixedDataSource'>
  dtype: <dtype: 'float32'>
  file_pattern: "gs://the-peoples-speech-west-europe/Librispeech/train/train.tfrecords-*"
  file_pattern_prefix: "gs://the-peoples-speech-west-europe/Librispeech"
  file_type: "tfrecord"
  fprop_dtype: None
  inference_driver_name: None
  is_inference: None
  name: "datasource"
  params_init: {
    method: "xavier"
    scale: 1.000001
    seed: None
  }
  random_seed: None
  skip_lp_regularization: None
  vn: {
    global_vn: False
    per_step_vn: False
    scale: None
    seed: None
  }
} and file_pattern 
I0731 06:15:10.187194 140120596608384 base_input_generator.py:776] infeed_bucket_batch_limit=[16] num_splits_per_client=8 bucket_batch_limit=[2]
I0731 06:15:10.187269 140120596608384 base_input_generator.py:798] infeed_bucket_batch_limit [16]
I0731 06:15:10.224626 140120596608384 base_input_generator.py:776] infeed_bucket_batch_limit=[16] num_splits_per_client=8 bucket_batch_limit=[2]
I0731 06:15:10.224836 140120596608384 base_input_generator.py:792] InfeedBatchSize: 16
I0731 06:15:10.224932 140120596608384 base_input_generator.py:776] infeed_bucket_batch_limit=[16] num_splits_per_client=8 bucket_batch_limit=[2]
I0731 06:15:10.224992 140120596608384 base_input_generator.py:792] InfeedBatchSize: 16
I0731 06:15:10.225066 140120596608384 base_input_generator.py:776] infeed_bucket_batch_limit=[16] num_splits_per_client=8 bucket_batch_limit=[2]
I0731 06:15:10.225112 140120596608384 base_input_generator.py:792] InfeedBatchSize: 16
I0731 06:15:10.261509 140120596608384 base_input_generator.py:219] CreateTpuEnqueueOps num_splits_per_client=8 num_devices_per_split=1 num_tpu_hosts=1 use_per_host_infeed=False
I0731 06:15:10.261709 140120596608384 base_input_generator.py:232] shards 8
I0731 06:15:10.261770 140120596608384 base_input_generator.py:248] tpu_emb_input_keys: []
I0731 06:15:10.261840 140120596608384 base_input_generator.py:249] num_infeed_hosts: 1
I0731 06:15:10.262133 140120596608384 base_input_generator.py:262] host_device: /task:0/device:CPU:0, batch: {'src': {'paddings': <tf.Tensor 'EnsureShape_1:0' shape=(16, 639) dtype=float32>, 'src_inputs': <tf.Tensor 'EnsureShape:0' shape=(16, 639, 80, 1) dtype=float32>}, 'tgt': {'ids': <tf.Tensor 'EnsureShape_2:0' shape=(16, 300) dtype=int32>, 'labels': <tf.Tensor 'EnsureShape_3:0' shape=(16, 300) dtype=int32>, 'paddings': <tf.Tensor 'EnsureShape_4:0' shape=(16, 300) dtype=float32>, 'weights': <tf.Tensor 'sub_5:0' shape=(16, 300) dtype=float32>}}
I0731 06:15:10.262463 140120596608384 base_input_generator.py:274] host_device: /task:0/device:CPU:0 infeed shapes: [TensorShape([16, 639]), TensorShape([16, 639, 80, 1]), TensorShape([16, 300]), TensorShape([16, 300]), TensorShape([16, 300]), TensorShape([16, 300])]
I0731 06:15:10.262544 140120596608384 base_input_generator.py:276] host_device: /task:0/device:CPU:0 infeed dtypes: [tf.float32, tf.float32, tf.int32, tf.int32, tf.float32, tf.float32]
I0731 06:15:10.278658 140120596608384 base_input_generator.py:326] input_ops_list [<tf.Operation 'InfeedQueue/enqueue/0' type=InfeedEnqueueTuple>, <tf.Operation 'InfeedQueue/enqueue/1' type=InfeedEnqueueTuple>, <tf.Operation 'InfeedQueue/enqueue/2' type=InfeedEnqueueTuple>, <tf.Operation 'InfeedQueue/enqueue/3' type=InfeedEnqueueTuple>, <tf.Operation 'InfeedQueue/enqueue/4' type=InfeedEnqueueTuple>, <tf.Operation 'InfeedQueue/enqueue/5' type=InfeedEnqueueTuple>, <tf.Operation 'InfeedQueue/enqueue/6' type=InfeedEnqueueTuple>, <tf.Operation 'InfeedQueue/enqueue/7' type=InfeedEnqueueTuple>]
I0731 06:15:10.393528 140120596608384 base_model.py:1071] Training parameters for <class 'lingvo.core.base_model.SingleTaskModel'>: {
  early_stop: {
    metric_history: {
      jobname: "eval_dev"
      local_filesystem: False
      logdir: "logs/galvez/tpu_1d"
      metric: "log_pplx"
      minimize: True
      name: "MetricHistory"
      tfevent_file: False
    }
    min_steps: 0
    name: "EarlyStop"
    tolerance: 0.0
    verbose: True
    window: 0
  }
  ema_decay: 0.0
  ema_decay_moving_vars: None
  enqueue_max_steps: -1
  init_from_checkpoint_rules: {}
  max_steps: 4000000
  save_interval_seconds: 600
  save_keep_checkpoint_every_n_hours: 0.5
  save_max_to_keep: 100
  start_up_delay_steps: 200
  summary_interval_steps: 100
  tpu_steps_per_loop: 20
}
I0731 06:15:10.398896 140120596608384 base_model.py:270] input_params: {
  allow_implicit_capture: None
  append_eos_frame: False
  bucket_adjust_every_n: 0
  bucket_batch_limit: [2]
  bucket_upper_bound: [639]
  cls: <class 'lingvo.tasks.asr.input_generator.AsrInput'>
  dtype: <dtype: 'float32'>
  file_buffer_size: 10000
  file_buffer_size_in_seconds: 0
  file_datasource: {
    allow_implicit_capture: None
    cls: <class 'lingvo.core.datasource.PrefixedDataSource'>
    dtype: <dtype: 'float32'>
    file_pattern: "train/train.tfrecords-*"
    file_pattern_prefix: "gs://the-peoples-speech-west-europe/Librispeech"
    file_type: "tfrecord"
    fprop_dtype: None
    inference_driver_name: None
    is_inference: None
    name: "datasource"
    params_init: {
      method: "xavier"
      scale: 1.000001
      seed: None
    }
    random_seed: None
    skip_lp_regularization: None
    vn: {
      global_vn: False
      per_step_vn: False
      scale: None
      seed: None
    }
  }
  file_parallelism: 16
  file_pattern: ""
  file_random_seed: 0
  flush_every_n: 0
  fprop_dtype: None
  frame_size: 80
  inference_driver_name: None
  is_inference: None
  name: "input"
  num_batcher_threads: 1
  num_partitions: None
  num_samples: 281241
  pad_to_max_seq_length: True
  params_init: {
    method: "xavier"
    scale: 1.000001
    seed: None
  }
  random_seed: None
  remote: {
    max_inflights_per_target: 32
    shardable_batch: False
  }
  repeat_count: -1
  require_sequential_order: False
  skip_create_child: True
  skip_lp_regularization: None
  source_max_length: 639
  target_max_length: 300
  tokenizer: {
    allow_implicit_capture: None
    append_eos: True
    cls: <class 'lingvo.core.tokenizers.AsciiTokenizer'>
    dtype: <dtype: 'float32'>
    fprop_dtype: None
    inference_driver_name: None
    is_inference: None
    name: "tokenizer"
    pad_to_max_length: True
    params_init: {
      method: "xavier"
      scale: 1.000001
      seed: None
    }
    random_seed: None
    skip_lp_regularization: None
    target_eos_id: 2
    target_sos_id: 1
    target_unk_id: 0
    target_wb_id: -1
    vn: {
      global_vn: False
      per_step_vn: False
      scale: None
      seed: None
    }
    vocab_size: 76
  }
  tokenizer_dict: {}
  tpu_infeed_parallelism: 1
  use_chaining: False
  use_partitioned_infeed_queue: False
  use_per_host_infeed: False
  use_within_batch_mixing: False
  vn: {
    global_vn: False
    per_step_vn: False
    scale: None
    seed: None
  }
}
I0731 06:15:10.400637 140120596608384 learner.py:380] Ignoring legacy param start_up_delay_steps=200 for optimization program
I0731 06:15:10.400761 140120596608384 learner.py:380] Ignoring legacy param max_steps=4000000 for optimization program
I0731 06:15:10.400829 140120596608384 learner.py:380] Ignoring legacy param tpu_steps_per_loop=20 for optimization program
I0731 06:15:10.400870 140120596608384 learner.py:380] Ignoring legacy param vn_start_step=20000 for optimization program
I0731 06:15:10.400906 140120596608384 learner.py:380] Ignoring legacy param vn_std=0.075 for optimization program
I0731 06:15:10.400947 140120596608384 learner.py:380] Ignoring legacy param early_stop={
  metric_history: {
    jobname: "eval_dev"
    local_filesystem: False
    logdir: "logs/galvez/tpu_1d"
    metric: "log_pplx"
    minimize: True
    name: "MetricHistory"
    tfevent_file: False
  }
  min_steps: 0
  name: "EarlyStop"
  tolerance: 0.0
  verbose: True
  window: 0
} for optimization program
I0731 06:15:10.401043 140120596608384 learner.py:380] Ignoring legacy param ema_decay=0.0 for optimization program
I0731 06:15:10.401085 140120596608384 learner.py:380] Ignoring legacy param ema_decay_moving_vars=None for optimization program
I0731 06:15:10.401126 140120596608384 learner.py:380] Ignoring legacy param init_from_checkpoint_rules={} for optimization program
I0731 06:15:10.401166 140120596608384 learner.py:380] Ignoring legacy param pruning_hparams_dict=None for optimization program
I0731 06:15:10.401205 140120596608384 learner.py:380] Ignoring legacy param enqueue_max_steps=-1 for optimization program
I0731 06:15:10.401242 140120596608384 learner.py:380] Ignoring legacy param save_interval_seconds=600 for optimization program
I0731 06:15:10.401286 140120596608384 learner.py:380] Ignoring legacy param save_max_to_keep=100 for optimization program
I0731 06:15:10.401324 140120596608384 learner.py:380] Ignoring legacy param save_keep_checkpoint_every_n_hours=0.5 for optimization program
I0731 06:15:10.401364 140120596608384 learner.py:380] Ignoring legacy param summary_interval_steps=100 for optimization program
I0731 06:15:10.401401 140120596608384 learner.py:380] Ignoring legacy param learner=None for optimization program
I0731 06:15:10.401906 140120596608384 learner.py:385] Learner params: allow_implicit_capture : NoneType
I0731 06:15:10.401977 140120596608384 learner.py:385] Learner params: bprop_variable_exclusion : NoneType
I0731 06:15:10.402023 140120596608384 learner.py:385] Learner params: bprop_variable_filter : NoneType
I0731 06:15:10.402094 140120596608384 learner.py:385] Learner params: clip_gradient_norm_to_value : 1.0
I0731 06:15:10.402133 140120596608384 learner.py:385] Learner params: clip_gradient_single_norm_to_value : 0.0
I0731 06:15:10.402170 140120596608384 learner.py:385] Learner params: cls : type/lingvo.core.learner/Learner
I0731 06:15:10.402207 140120596608384 learner.py:385] Learner params: colocate_gradients_with_ops : True
I0731 06:15:10.402244 140120596608384 learner.py:385] Learner params: dtype : float32
I0731 06:15:10.402288 140120596608384 learner.py:385] Learner params: fprop_dtype : NoneType
I0731 06:15:10.402325 140120596608384 learner.py:385] Learner params: gate_gradients : False
I0731 06:15:10.402361 140120596608384 learner.py:385] Learner params: grad_aggregation_method : 1
I0731 06:15:10.402398 140120596608384 learner.py:385] Learner params: grad_norm_to_clip_to_zero : 100.0
I0731 06:15:10.402435 140120596608384 learner.py:385] Learner params: grad_norm_tracker : NoneType
I0731 06:15:10.402471 140120596608384 learner.py:385] Learner params: inference_driver_name : NoneType
I0731 06:15:10.402507 140120596608384 learner.py:385] Learner params: is_inference : NoneType
I0731 06:15:10.402544 140120596608384 learner.py:385] Learner params: l1_regularizer_weight : NoneType
I0731 06:15:10.402580 140120596608384 learner.py:385] Learner params: l2_regularizer_weight : NoneType
I0731 06:15:10.402617 140120596608384 learner.py:385] Learner params: learning_rate : 0.00025
I0731 06:15:10.402654 140120596608384 learner.py:385] Learner params: lr_schedule.allow_implicit_capture : NoneType
I0731 06:15:10.402690 140120596608384 learner.py:385] Learner params: lr_schedule.cls : type/lingvo.core.schedule/ContinuousSchedule
I0731 06:15:10.402727 140120596608384 learner.py:385] Learner params: lr_schedule.dtype : float32
I0731 06:15:10.402763 140120596608384 learner.py:385] Learner params: lr_schedule.fprop_dtype : NoneType
I0731 06:15:10.402799 140120596608384 learner.py:385] Learner params: lr_schedule.half_life_steps : 100000
I0731 06:15:10.402836 140120596608384 learner.py:385] Learner params: lr_schedule.inference_driver_name : NoneType
I0731 06:15:10.402872 140120596608384 learner.py:385] Learner params: lr_schedule.initial_value : 1.0
I0731 06:15:10.402909 140120596608384 learner.py:385] Learner params: lr_schedule.is_inference : NoneType
I0731 06:15:10.402945 140120596608384 learner.py:385] Learner params: lr_schedule.min : 0.01
I0731 06:15:10.402982 140120596608384 learner.py:385] Learner params: lr_schedule.name : 'LRSched'
I0731 06:15:10.403017 140120596608384 learner.py:385] Learner params: lr_schedule.params_init.method : 'xavier'
I0731 06:15:10.403054 140120596608384 learner.py:385] Learner params: lr_schedule.params_init.scale : 1.000001
I0731 06:15:10.403135 140120596608384 learner.py:385] Learner params: lr_schedule.params_init.seed : NoneType
I0731 06:15:10.403173 140120596608384 learner.py:385] Learner params: lr_schedule.random_seed : NoneType
I0731 06:15:10.403209 140120596608384 learner.py:385] Learner params: lr_schedule.skip_lp_regularization : NoneType
I0731 06:15:10.403245 140120596608384 learner.py:385] Learner params: lr_schedule.start_step : 50000
I0731 06:15:10.403286 140120596608384 learner.py:385] Learner params: lr_schedule.vn.global_vn : False
I0731 06:15:10.403323 140120596608384 learner.py:385] Learner params: lr_schedule.vn.per_step_vn : False
I0731 06:15:10.403359 140120596608384 learner.py:385] Learner params: lr_schedule.vn.scale : NoneType
I0731 06:15:10.403396 140120596608384 learner.py:385] Learner params: lr_schedule.vn.seed : NoneType
I0731 06:15:10.403431 140120596608384 learner.py:385] Learner params: name : 'loss'
I0731 06:15:10.403468 140120596608384 learner.py:385] Learner params: optimizer.allow_implicit_capture : NoneType
I0731 06:15:10.403504 140120596608384 learner.py:385] Learner params: optimizer.beta1 : 0.9
I0731 06:15:10.403539 140120596608384 learner.py:385] Learner params: optimizer.beta2 : 0.999
I0731 06:15:10.403577 140120596608384 learner.py:385] Learner params: optimizer.cls : type/lingvo.core.optimizer/Adam
I0731 06:15:10.403612 140120596608384 learner.py:385] Learner params: optimizer.dtype : float32
I0731 06:15:10.403648 140120596608384 learner.py:385] Learner params: optimizer.epsilon : 1e-06
I0731 06:15:10.403683 140120596608384 learner.py:385] Learner params: optimizer.fprop_dtype : NoneType
I0731 06:15:10.403719 140120596608384 learner.py:385] Learner params: optimizer.inference_driver_name : NoneType
I0731 06:15:10.403755 140120596608384 learner.py:385] Learner params: optimizer.is_inference : NoneType
I0731 06:15:10.403790 140120596608384 learner.py:385] Learner params: optimizer.name : 'Adam'
I0731 06:15:10.403826 140120596608384 learner.py:385] Learner params: optimizer.params_init.method : 'xavier'
I0731 06:15:10.403862 140120596608384 learner.py:385] Learner params: optimizer.params_init.scale : 1.000001
I0731 06:15:10.403914 140120596608384 learner.py:385] Learner params: optimizer.params_init.seed : NoneType
I0731 06:15:10.403951 140120596608384 learner.py:385] Learner params: optimizer.random_seed : NoneType
I0731 06:15:10.403987 140120596608384 learner.py:385] Learner params: optimizer.skip_lp_regularization : NoneType
I0731 06:15:10.404023 140120596608384 learner.py:385] Learner params: optimizer.use_bf16_gradients_ar : False
I0731 06:15:10.404060 140120596608384 learner.py:385] Learner params: optimizer.vn.global_vn : False
I0731 06:15:10.404095 140120596608384 learner.py:385] Learner params: optimizer.vn.per_step_vn : False
I0731 06:15:10.404131 140120596608384 learner.py:385] Learner params: optimizer.vn.scale : NoneType
I0731 06:15:10.404167 140120596608384 learner.py:385] Learner params: optimizer.vn.seed : NoneType
I0731 06:15:10.404205 140120596608384 learner.py:385] Learner params: params_init.method : 'xavier'
I0731 06:15:10.404241 140120596608384 learner.py:385] Learner params: params_init.scale : 1.000001
I0731 06:15:10.404282 140120596608384 learner.py:385] Learner params: params_init.seed : NoneType
I0731 06:15:10.404319 140120596608384 learner.py:385] Learner params: random_seed : NoneType
I0731 06:15:10.404355 140120596608384 learner.py:385] Learner params: scale_gradients : False
I0731 06:15:10.404391 140120596608384 learner.py:385] Learner params: skip_lp_regularization : NoneType
I0731 06:15:10.404427 140120596608384 learner.py:385] Learner params: skip_zero_gradients : NoneType
I0731 06:15:10.404463 140120596608384 learner.py:385] Learner params: vn.global_vn : False
I0731 06:15:10.404499 140120596608384 learner.py:385] Learner params: vn.per_step_vn : False
I0731 06:15:10.404534 140120596608384 learner.py:385] Learner params: vn.scale : NoneType
I0731 06:15:10.404570 140120596608384 learner.py:385] Learner params: vn.seed : NoneType
I0731 06:15:10.404606 140120596608384 learner.py:385] Learner params: 
W0731 06:15:10.412930 140120596608384 py_utils.py:1550] WARNING!!! var wm is using the default xavier initializer. Make sure this is intended.
I0731 06:15:10.423745 140120596608384 py_utils.py:1710] Creating var librispeech/fwd_rnn_cell_L0/wm/var:0 shape=(144, 256) on device /job:trainer_client
I0731 06:15:10.430270 140120596608384 py_utils.py:1710] Creating var librispeech/fwd_rnn_cell_L0/b/var:0 shape=(256,) on device /job:trainer_client
W0731 06:15:10.436654 140120596608384 py_utils.py:1550] WARNING!!! var w is using the default xavier initializer. Make sure this is intended.
I0731 06:15:10.445919 140120596608384 py_utils.py:1710] Creating var librispeech/project_to_vocab_size/w/var:0 shape=(64, 76) on device /job:trainer_client
I0731 06:15:10.451573 140120596608384 py_utils.py:1710] Creating var librispeech/project_to_vocab_size/b/var:0 shape=(76,) on device /job:trainer_client
I0731 06:15:11.164406 140120596608384 base_input_generator.py:776] infeed_bucket_batch_limit=[16] num_splits_per_client=8 bucket_batch_limit=[2]
I0731 06:15:11.164623 140120596608384 base_input_generator.py:792] InfeedBatchSize: 16
I0731 06:15:11.164701 140120596608384 base_input_generator.py:140] GlobalBatchSize 16
I0731 06:15:11.167000 140120596608384 learner.py:176] loss: bprop variable: librispeech/project_to_vocab_size/b/var:0
I0731 06:15:11.167182 140120596608384 learner.py:176] loss: bprop variable: librispeech/project_to_vocab_size/w/var:0
I0731 06:15:11.167279 140120596608384 learner.py:176] loss: bprop variable: librispeech/fwd_rnn_cell_L0/b/var:0
I0731 06:15:11.167340 140120596608384 learner.py:176] loss: bprop variable: librispeech/fwd_rnn_cell_L0/wm/var:0
I0731 06:15:12.038653 140120596608384 base_input_generator.py:373] tpu_emb_input_keys: []
I0731 06:15:12.093513 140120596608384 trainer.py:662] Trainer number of enqueue ops: 1
I0731 06:15:12.610399 140120596608384 trainer.py:1609] Starting runners
I0731 06:15:12.611114 140118128961280 base_runner.py:192] trainer started.
I0731 06:15:12.611469 140120596608384 trainer.py:1618] Total num runner.enqueue_ops: 1
I0731 06:15:12.611629 140120596608384 trainer.py:1622] Starting enqueue op group_deps
I0731 06:15:12.612236 140118112175872 base_runner.py:192] trainer/enqueue_op/group_deps started.
I0731 06:15:12.612458 140120596608384 trainer.py:1630] Waiting for runners to finish...
I0731 06:15:12.612614 140120596608384 trainer.py:1632] Waiting for thread to finish: <__main__.TrainerTpu object at 0x7f6fcc510650>
I0731 06:15:21.605617 140118128961280 trainer.py:822] TrainerTpu: Force restore or initialize.
I0731 06:15:21.674913 140118128961280 checkpointer.py:146] Uninitialized var list: [b'beta1_power', b'beta2_power', b'global_step', b'librispeech/fwd_rnn_cell_L0/b/var', b'librispeech/fwd_rnn_cell_L0/b/var/Adam', b'librispeech/fwd_rnn_cell_L0/b/var/Adam_1', b'librispeech/fwd_rnn_cell_L0/wm/var', b'librispeech/fwd_rnn_cell_L0/wm/var/Adam', b'librispeech/fwd_rnn_cell_L0/wm/var/Adam_1', b'librispeech/project_to_vocab_size/b/var', b'librispeech/project_to_vocab_size/b/var/Adam', b'librispeech/project_to_vocab_size/b/var/Adam_1', b'librispeech/project_to_vocab_size/w/var', b'librispeech/project_to_vocab_size/w/var/Adam', b'librispeech/project_to_vocab_size/w/var/Adam_1']
I0731 06:15:21.723309 140118128961280 base_runner.py:111] <b>Retrying as expected</b> trainer exception: Cannot add function 'while_cond_208' because a different function with the same name already exists.

I0731 06:15:22.726761 140118128961280 retry.py:71] Retry: caught exception: _RunLoop while running tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot add function 'while_cond_208' because a different function with the same name already exists.
. Call failed at (most recent call last):
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
Traceback for above exception (most recent call last):
  File "/home/ws15dgalvez/lingvo-copy/bazel-bin/lingvo/trainer.runfiles/__main__/lingvo/core/retry.py", line 53, in Wrapper
    return func(*args, **kwargs)
  File "/home/ws15dgalvez/lingvo-copy/bazel-bin/lingvo/trainer.runfiles/__main__/lingvo/base_runner.py", line 193, in _RunLoop
    loop_func(*loop_args)
  File "/home/ws15dgalvez/lingvo-copy/bazel-bin/lingvo/trainer.runfiles/__main__/lingvo/trainer.py", line 823, in _Loop
    self.checkpointer.Restore(sess, force_reinitialize=True)
  File "/home/ws15dgalvez/lingvo-copy/bazel-bin/lingvo/trainer.runfiles/__main__/lingvo/core/checkpointer.py", line 162, in Restore
    sess.run(tf.global_variables_initializer())
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 958, in run
    run_metadata_ptr)
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1181, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1359, in _do_run
    run_metadata)
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1384, in _do_call
    raise type(e)(node_def, op, message)
Waiting for 1.52 seconds before retrying.
I0731 06:15:22.726980 140118128961280 base_runner.py:192] trainer started.
I0731 06:15:40.755815 140118128961280 trainer.py:822] TrainerTpu: Force restore or initialize.
I0731 06:15:40.809947 140118128961280 checkpointer.py:146] Uninitialized var list: [b'beta1_power', b'beta2_power', b'global_step', b'librispeech/fwd_rnn_cell_L0/b/var', b'librispeech/fwd_rnn_cell_L0/b/var/Adam', b'librispeech/fwd_rnn_cell_L0/b/var/Adam_1', b'librispeech/fwd_rnn_cell_L0/wm/var', b'librispeech/fwd_rnn_cell_L0/wm/var/Adam', b'librispeech/fwd_rnn_cell_L0/wm/var/Adam_1', b'librispeech/project_to_vocab_size/b/var', b'librispeech/project_to_vocab_size/b/var/Adam', b'librispeech/project_to_vocab_size/b/var/Adam_1', b'librispeech/project_to_vocab_size/w/var', b'librispeech/project_to_vocab_size/w/var/Adam', b'librispeech/project_to_vocab_size/w/var/Adam_1']
I0731 06:15:40.852242 140118128961280 base_runner.py:111] <b>Retrying as expected</b> trainer exception: Cannot add function 'while_cond_208' because a different function with the same name already exists.

I0731 06:15:42.377947 140118128961280 retry.py:71] Retry: caught exception: _RunLoop while running tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot add function 'while_cond_208' because a different function with the same name already exists.
. Call failed at (most recent call last):
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
Traceback for above exception (most recent call last):
  File "/home/ws15dgalvez/lingvo-copy/bazel-bin/lingvo/trainer.runfiles/__main__/lingvo/core/retry.py", line 53, in Wrapper
    return func(*args, **kwargs)
  File "/home/ws15dgalvez/lingvo-copy/bazel-bin/lingvo/trainer.runfiles/__main__/lingvo/base_runner.py", line 193, in _RunLoop
    loop_func(*loop_args)
  File "/home/ws15dgalvez/lingvo-copy/bazel-bin/lingvo/trainer.runfiles/__main__/lingvo/trainer.py", line 823, in _Loop
    self.checkpointer.Restore(sess, force_reinitialize=True)
  File "/home/ws15dgalvez/lingvo-copy/bazel-bin/lingvo/trainer.runfiles/__main__/lingvo/core/checkpointer.py", line 162, in Restore
    sess.run(tf.global_variables_initializer())
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 958, in run
    run_metadata_ptr)
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1181, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1359, in _do_run
    run_metadata)
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1384, in _do_call
    raise type(e)(node_def, op, message)
Waiting for 2.30 seconds before retrying.
I0731 06:15:42.378174 140118128961280 base_runner.py:192] trainer started.
I0731 06:15:58.823472 140118128961280 trainer.py:822] TrainerTpu: Force restore or initialize.
I0731 06:15:58.875587 140118128961280 checkpointer.py:146] Uninitialized var list: [b'beta1_power', b'beta2_power', b'global_step', b'librispeech/fwd_rnn_cell_L0/b/var', b'librispeech/fwd_rnn_cell_L0/b/var/Adam', b'librispeech/fwd_rnn_cell_L0/b/var/Adam_1', b'librispeech/fwd_rnn_cell_L0/wm/var', b'librispeech/fwd_rnn_cell_L0/wm/var/Adam', b'librispeech/fwd_rnn_cell_L0/wm/var/Adam_1', b'librispeech/project_to_vocab_size/b/var', b'librispeech/project_to_vocab_size/b/var/Adam', b'librispeech/project_to_vocab_size/b/var/Adam_1', b'librispeech/project_to_vocab_size/w/var', b'librispeech/project_to_vocab_size/w/var/Adam', b'librispeech/project_to_vocab_size/w/var/Adam_1']
I0731 06:15:58.920868 140118128961280 base_runner.py:111] <b>Retrying as expected</b> trainer exception: Cannot add function 'while_cond_208' because a different function with the same name already exists.

I0731 06:16:01.220456 140118128961280 retry.py:71] Retry: caught exception: _RunLoop while running tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot add function 'while_cond_208' because a different function with the same name already exists.
. Call failed at (most recent call last):
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/threading.py", line 890, in _bootstrap
    self._bootstrap_inner()
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
Traceback for above exception (most recent call last):
  File "/home/ws15dgalvez/lingvo-copy/bazel-bin/lingvo/trainer.runfiles/__main__/lingvo/core/retry.py", line 53, in Wrapper
    return func(*args, **kwargs)
  File "/home/ws15dgalvez/lingvo-copy/bazel-bin/lingvo/trainer.runfiles/__main__/lingvo/base_runner.py", line 193, in _RunLoop
    loop_func(*loop_args)
  File "/home/ws15dgalvez/lingvo-copy/bazel-bin/lingvo/trainer.runfiles/__main__/lingvo/trainer.py", line 823, in _Loop
    self.checkpointer.Restore(sess, force_reinitialize=True)
  File "/home/ws15dgalvez/lingvo-copy/bazel-bin/lingvo/trainer.runfiles/__main__/lingvo/core/checkpointer.py", line 162, in Restore
    sess.run(tf.global_variables_initializer())
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 958, in run
    run_metadata_ptr)
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1181, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1359, in _do_run
    run_metadata)
  File "/home/ws15dgalvez/miniconda3/envs/100k-hours-lingvo/lib/python3.7/site-packages/tensorflow/python/client/session.py", line 1384, in _do_call
    raise type(e)(node_def, op, message)
Waiting for 3.54 seconds before retrying.
I0731 06:16:01.220690 140118128961280 base_runner.py:192] trainer started.
